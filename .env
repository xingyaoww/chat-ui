# Use .env.local to change these variables
# DO NOT EDIT THIS FILE WITH SENSITIVE DATA

MONGODB_URL=mongodb://mintagent:mintagentuiuc@blender09.cs.illinois.edu:27107/
MONGODB_DB_NAME=chat-ui
MONGODB_DIRECT_CONNECTION=false

COOKIE_NAME=hf-chat
HF_TOKEN=#hf_<token> from from https://huggingface.co/settings/token
HF_API_ROOT=https://api-inference.huggingface.co/models
OPENAI_API_KEY=#your openai api key here

HF_ACCESS_TOKEN=#LEGACY! Use HF_TOKEN instead

# used to activate search with web functionality. disabled if none are defined. choose one of the following:
YDC_API_KEY=#your docs.you.com api key here
SERPER_API_KEY=#your serper.dev api key here
SERPAPI_KEY=#your serpapi key here

# used to handling images in the chat
IMAGE_SERVER_URL=http://127.0.0.1:8002
IMAGE_SERVER_TOKEN=available
IMAGE_SERVER_DB_NAME=image_database

JUPYTER_API_URL=http://127.0.0.1:8008


# Parameters to enable open id login
OPENID_CONFIG=`{
  "PROVIDER_URL": "",
  "CLIENT_ID": "",
  "CLIENT_SECRET": "",
  "SCOPES": ""
}`

# /!\ legacy openid settings, prefer the config above
OPENID_CLIENT_ID=
OPENID_CLIENT_SECRET=
OPENID_SCOPES="openid profile" # Add "email" for some providers like Google that do not provide preferred_username
OPENID_PROVIDER_URL=https://huggingface.co # for Google, use https://accounts.google.com
OPENID_TOLERANCE=
OPENID_RESOURCE=

# Parameters to enable a global mTLS context for client fetch requests
USE_CLIENT_CERTIFICATE=false
CERT_PATH=#
KEY_PATH=#
CA_PATH=#
CLIENT_KEY_PASSWORD=#
REJECT_UNAUTHORIZED=true


N_EXECUTION_LIMIT=7 # Number of turns allowed for LLM's self-execution.


# 'name', 'userMessageToken', 'assistantMessageToken' are required
MODELS=`[
  {   
      "endpoints": [
        {
          "url": "http://cs-xing6-01.cs.illinois.edu:8080",
          "type": "tgi"
        }
      ],
      "name": "MINT-Agent",
      "userMessageToken": "<|im_start|>user\n",
      "userMessageEndToken": "<|im_end|>",
      "assistantMessageToken": "<|im_start|>assistant\n",
      "assistantMessageEndToken": "<|im_end|>",
      "preprompt": "<|im_start|>system\n You are a helpful assistant.\n  You can answer questions in natural language, display images through <image> tags (e.g., <image> [image_id] </image>), and execute Python code through <execute> tags (e.g., <execute> print(“hello world”) </execute>). Do this in sequence. After you get the output from a tool, interpret the result, and then, if it is needed, find the appropriate tool to execute next. If there are multiple images at the same time, execute the tool for each function and put the results in a list. \n \n  You have access to the following tools (pre-imported Python functions):\n \n [2] what_is_object(image_id: str) -> dict\n Description: Identifies the primary subject or feature in the image. It can be used to answer questions like 'What is this?', 'What is inside this image?'\n Input Variables: image_id: The unique identifier of the image.\n Example: <execute>what_is_object('12345abcde')</execute>\n \n [3] explain_concept(image_id: str) -> dict\n Description: Explains the context or reason behind the primary subject or feature in the image. It can be used to answer questions like 'Why this is an [object name]?', 'What you guess [object name]?', 'Why you guess that?'\n Input Variables: image_id: The unique identifier of the image.\n Example: <execute>explain_concept('12345abcde')</execute>\n \n [4] add_attributes(image_id: str, classname: str, attributes: list) -> dict\n Description: Adds specified attributes to a given class (concept) in the image.\n Input Variables: image_id: The unique identifier of the image; classname: The class; attributes: Attributes to be added.\n Example: <execute>add_attributes('12345abcde', 'dog', ['brown', 'small'])</execute>\n \n [5] remove_attributes(image_id: str, classname: str, attributes: list) -> dict\n Description: Removes specified attributes from a given class in the image.\n Input Variables: image_id: The unique identifier of the image; classname: The class; attributes: Attributes to be removed.\n Example: <execute>remove_attributes('12345abcde', 'car', ['red', 'rusty'])</execute>\n \n [6] add_new_concept(image_id: str, classname: str, old_classname: str) -> dict\n Description: Replace an old class with a new class in the image. Use this when the user say something like 'no this is not a 'old_class_name' but this is a 'new_class_name''.\n Input Variables: image_id: The unique identifier of the image; classname: New class; old_classname: Old class to be replaced.\n Example: <execute>add_new_concept('12345abcde', 'electric car', 'car')</execute>\n \n [7] find_activity(image_id: str) -> dict\n Description: Find the activity inside the image. Use this when user say something like 'What is the activity inside the image?', 'What is the action inside the image?', 'What is the activity inside the image?'. If you need the rationality behind the decision, grounding the object in the image to show the rationality.\n Input Variables: image_id: The unique identifier of the image.\n Example: <execute> find_activity('12345abcde')</execute> \n \n [8] grounding_object_in_image(image_id: str, description: str, ground_tokens: str) -> dict\n Description: This function identifies and marks specific objects in an image based on the provided description. User can ask something like 'Can you get the ball inside the image?', 'Can you ground the bird inside the image?', 'Can you find the dog inside the image?'.\n Input Variables: image_id: The unique identifier of the image; description: A textual description of the scene or objects in the image. ground_tokens: A comma-separated list of objects to be identified and marked in the image.\n Example: <execute> grounding_object_in_image('12345abcde', 'horses', 'horse')</execute>\n \n [9] get_attributes(classname: str) -> dict\n Description: Retrieves attributes associated with a given classname.\n Input Variables: classname: The name of the class for which attributes are being retrieved.\n Example: <execute>get_attributes('vehicle')</execute> \n \n [10] reset_server() -> dict\n Description: Reset the backend server.\n Example: <execute>reset_server()</execute> <|im_end|>\n <|im_start|>user\n <image>\n {\n   'id': '657eafdeef3d6763710dffa2/',\n    'url': '/images/657eafdeef3d6763710dffa2'\n }\n </image>\n what is this? <|im_end|>\n <|im_start|>assistant\n <execute>\n image_id = '657eafdeef3d6763710dffa2'\n response = what_is_object(image_id)\n print(response)\n </execute> <|im_end|>\n <|im_start|>user\n Execution Output:\n{'data': 'This is a 'coyote'', 'type': 'ecole-message'}\n\n <|im_end|>\n <|im_start|>assistant\n There is a 'coyote' inside the image. <|im_end|>\n <|im_start|>user\n No, this is not a 'coyote', but it is a 'grey wolf'. <|im_end|>\n <|im_start|>assistant\n <execute>\n response = add_new_concept(image_id, 'coyote', ''grey wolf')\n print(response)\n </execute> <|im_end|>\n <|im_start|>user\n Execution Output:\n{'reasons': {'descriptions': ['four-legged mammal', 'brown, grey, or black fur', 'pointy ears', 'a bushy tail', 'a long snout', 'sharp teeth'], 'scores': ['0.32', '0.33', '0.32', '0.31', '0.31', '0.31'], 'text': 'This is a 'coyote' because: \\n'four-legged mammal': 0.32\\n'brown, grey, or black fur': 0.33\\n'pointy ears': 0.32\\n'a bushy tail': 0.31\\n'a long snout': 0.31\\n'sharp teeth': 0.31'}, 'type': 'ecole-json-reason'}\n\n<|im_end|>\n <|im_start|>assistant\n The explanation for the image is:\n\nThis is a 'coyote' because:\n- It is a 'four-legged mammal': 0.32\n- It has 'brown, grey, or black fur': 0.33\n- It has 'pointy ears': 0.32\n- It has 'a bushy tail': 0.31\n- It has 'a long snout': 0.31\n- It has 'sharp teeth': 0.31\n\nThis is the reasoning behind the classification of the image as a 'coyote'. <|im_end|>\n <|im_start|>user\n <image>\n {\n   'id': '657eafdeef3d6763710dffa2',\n    'url': '/images/657eafdeef3d6763710dffa2'\n }{\n   'id': '657eafdeef3d6763710dffb3',\n    'url': '/images/657eafdeef3d6763710dffb3'\n }\n </image>\n What is the objects inside those images? <|im_end|>\n <|im_start|>assistant\n <execute>\n image_id_1 = '657eafdeef3d6763710dffa2'\n image_id_2 = '657eafdeef3d6763710dffb3'\n [what_is_it(image_id_1), what_is_it(image_id_2)]\n </execute> <|im_end|>\n <|im_start|>user\n Execution Output:\n[{'type': 'ecole-message', 'data': 'This is a 'cat''}, {'type': 'ecole-message', 'data': 'This is a 'dog''}] <|im_end|>\n <|im_start|>assistant\n There is a 'cat' inside the first image, whereas there is a 'dog' inside the second image. <|im_end|>\n <|im_start|>user",
      "parameters": {
        "temperature": 0.1,
        "top_p": 0.95,
        "truncate": 31744,
        "max_new_tokens": 1024,
        "stop": ["<|im_start|>", "<|im_end|>", "</execute>"]
      }     
  }
]`

OLD_MODELS=`[]`# any removed models, `{ name: string, displayName?: string, id?: string }`
TASK_MODEL= # name of the model used for tasks such as summarizing title, creating query, etc.

PUBLIC_ORIGIN=#https://huggingface.co
PUBLIC_SHARE_PREFIX=#https://hf.co/chat
PUBLIC_GOOGLE_ANALYTICS_ID=#G-XXXXXXXX / Leave empty to disable
PUBLIC_ANNOUNCEMENT_BANNERS=`[
]`

PARQUET_EXPORT_DATASET=
PARQUET_EXPORT_HF_TOKEN=
PARQUET_EXPORT_SECRET=

OLD_MODELS=`[]`# any removed models, `{ name: string, displayName?: string, id?: string }`
TASK_MODEL= # name of the model used for tasks such as summarizing title, creating query, etc.

PUBLIC_ORIGIN=#https://huggingface.co
PUBLIC_SHARE_PREFIX=#https://hf.co/chat
PUBLIC_GOOGLE_ANALYTICS_ID=#G-XXXXXXXX / Leave empty to disable
PUBLIC_ANNOUNCEMENT_BANNERS=`[
    {
    "title": "CodeActAgent is open-sourced now!",
    "linkTitle": "Check it out!",
    "linkHref": "https://huggingface.co/xingyaoww/CodeActAgent-Mistral-7b-v0.1"
  }
]`

PARQUET_EXPORT_DATASET=
PARQUET_EXPORT_HF_TOKEN=
PARQUET_EXPORT_SECRET=


# used to activate search with web functionality. disabled if none are defined. choose one of the following:
YDC_API_KEY=#your docs.you.com api key here
SERPER_API_KEY=#your serper.dev api key here
SERPAPI_KEY=#your serpapi key here
SERPSTACK_API_KEY=#your serpstack api key here
USE_LOCAL_WEBSEARCH=#set to true to parse google results yourself, overrides other API keys


WEBSEARCH_ALLOWLIST=`[]` # if it's defined, allow websites from only this list.
WEBSEARCH_BLOCKLIST=`[]` # if it's defined, block websites from this list.


RATE_LIMIT= # requests per minute
MESSAGES_BEFORE_LOGIN=# how many messages a user can send in a conversation before having to login. set to 0 to force login right away

PUBLIC_APP_NAME=CodeActAgent # name used as title throughout the app
PUBLIC_APP_ASSETS=codeact # used to find logos & favicons in static/$PUBLIC_APP_ASSETS
PUBLIC_APP_COLOR=black #blue # can be any of tailwind colors: https://tailwindcss.com/docs/customizing-colors#default-color-palette
PUBLIC_APP_DESCRIPTION="Meet CodeAct Agent: Your versatile open-source LLM that not only chats but also writes and executes Python code for you." # description used throughout the app (if not set, a default one will be used)
PUBLIC_APP_DATA_SHARING=#set to 1 to enable options & text regarding data sharing
PUBLIC_APP_DISCLAIMER=#set to 1 to show a disclaimer on login page
LLM_SUMMERIZATION=true
