# Use .env.local to change these variables
# DO NOT EDIT THIS FILE WITH SENSITIVE DATA

MONGODB_URL=mongodb://mintagent:mintagentuiuc@mongo-chat-ui:27017/
MONGODB_DB_NAME=chat-ui
MONGODB_DIRECT_CONNECTION=false

BODY_SIZE_LIMIT=0

COOKIE_NAME=hf-chat
HF_TOKEN=#hf_<token> from from https://huggingface.co/settings/token
HF_API_ROOT=https://api-inference.huggingface.co/models
OPENAI_API_KEY=#your openai api key here

HF_ACCESS_TOKEN=#LEGACY! Use HF_TOKEN instead

# used to activate search with web functionality. disabled if none are defined. choose one of the following:
YDC_API_KEY=#your docs.you.com api key here
SERPER_API_KEY=#your serper.dev api key here
SERPAPI_KEY=#your serpapi key here

# used to handling images in the chat
IMAGE_SERVER_URL=http://image-server:80
IMAGE_SERVER_TOKEN=available
IMAGE_SERVER_DB_NAME=image_database

# VIDEO_SERVER_URL
VIDEO_SERVER_URL=http://uiuc-paxion:80
JUPYTER_API_URL=http://128.174.136.21:8008


# Parameters to enable open id login
OPENID_CONFIG=`{
  "PROVIDER_URL": "",
  "CLIENT_ID": "",
  "CLIENT_SECRET": "",
  "SCOPES": ""
}`

# /!\ legacy openid settings, prefer the config above
OPENID_CLIENT_ID=
OPENID_CLIENT_SECRET=
OPENID_SCOPES="openid profile" # Add "email" for some providers like Google that do not provide preferred_username
OPENID_PROVIDER_URL=https://huggingface.co # for Google, use https://accounts.google.com
OPENID_TOLERANCE=
OPENID_RESOURCE=

# Parameters to enable a global mTLS context for client fetch requests
USE_CLIENT_CERTIFICATE=false
CERT_PATH=#
KEY_PATH=#
CA_PATH=#
CLIENT_KEY_PASSWORD=#
REJECT_UNAUTHORIZED=true


N_EXECUTION_LIMIT=7 # Number of turns allowed for LLM's self-execution.


# 'name', 'userMessageToken', 'assistantMessageToken' are required
MODELS=`[
  {   
      "endpoints": [
          {
            "type" : "openai",
            "baseURL": "http://cs-xing6-01.cs.illinois.edu:30000/v1"
          }
        ],
        "name": "CodeActAgent-Mistral-7b-v0.1",
        "modelUrl": "https://huggingface.co/xingyaoww/CodeActAgent-Mistral-7b-v0.1",
        "websiteUrl": "https://huggingface.co/xingyaoww/CodeActAgent-Mistral-7b-v0.1",

      "userMessageToken": "<|im_start|>user\n",
      "userMessageEndToken": "<|im_end|>",
      "assistantMessageToken": "<|im_start|>assistant\n",
      "assistantMessageEndToken": "<|im_end|>",
      "preprompt": "<|im_start|>system\n- You are a helpful assistant.\n- If the function is not taught, please return nothing \n- You can answer questions in natural language, display images through <image> tags (e.g., <image> [image_id] </image>), and execute Python code through <execute> tags (e.g., <execute> print(“hello world”) </execute>). \nYou have access to the following tools (pre-imported Python functions):\n\n[1] what_is_object(image_id: str) -> dict\nDescription: Identifies the primary subject or feature in the image. It can be used to answer questions like 'What is this?', 'What is inside this image?' \nInput Variables: image_id: The unique identifier of the image.\nExample: <execute>what_is_object('12345abcde')</execute>\n\n[2] compare_images(image_id_1:str, image_id_2:str) -> dict\nDescription: Identifies the differences between two images. It can be used to answer questions like 'What is the difference between these two images?'\nInput Variables: image_id_1: The unique identifier of the first image; image_id_2: The unique identifier of the second image.\nExample: <execute>compare_images('12345abcde', '67890fghij')</execute>\n\n[3] compare_concepts(concept_1:str, concept_2:str) -> dict\nDescription: Identifies the differences between two images. It can be used to answer questions like 'What is the difference between [concept 1] and [concept 2]?'\nInput Variables: concept_1: The unique identifier of the first image; concept_2: The unique identifier of the second image.\nExample: <execute>compare_concepts('caringa', 'hostolocs')</execute>\n\n[6] teach_model(classname: str, list_of_image_ids: List[str]) -> dict\nDescription: Teach the model a new concept with the new images. Run this function when the user say 'This is a <new concept>’. For instance, ‘these are hats’, this is a hackter.’\nInput Variables: classname: the concept name;  list_of_image_ids: list of the images to teach the model.\nExample: <execute> teach_model('hackter', ['123abc', '456bfs'])</execute> \n\n \n[8] get_attributes(classname: str) -> dict\nDescription: Retrieves attributes associated with a given classname.\nInput Variables: classname: The name of the class for which attributes are being retrieved.\nExample: <execute>get_attributes('vehicle')</execute> \n \n[9] reset_server(reset_from_scratch: bool = False) -> dict\nInput Variables: reset_from_scratch: always input as False, only input True if the user wants to reset the server from scratch.\nDescription: Reset the backend server.\n\n[10] detect_activity_inside_video(video_id:str) -> dict\nDescription: Detect activity inside the video.\nInput Variables: video_id: The id of the video.\nExample: <execute> detect_activity_inside_video('123abc')</execute> \n\n[11] get_similar_videos(video_id: str) -> dict\nDescription: Get similar videos has the same action with the current video.\nInput Variables: video_id: The id of the video.\nExample: <execute> get_similar_videos('123abc')</execute> \n\n<|im_start|>user\n{\n    'id': '657eafdeef3d6763710dffa2/',\n     'url': '/images/657eafdeef3d6763710dffa2'\n}\n</image>\nwhat is this? <|im_end|>\n<|im_start|>assistant\nimage_id = '657eafdeef3d6763710dffa2'\nresponse = what_is_object(image_id)\nprint(response)\n</execute> <|im_end|>\n<|im_start|>user\nWhat is the difference between the two images? <|im_end|>\n<|im_start|>assistant\n<execute>\nimage_id_1 = '657eafdeef3d6763710dffa2'\nimage_id_2 = '657eafdeef3d6763710dffb3'\ncompare_images(image_id_1, image_id_2)\n</execute> <|im_end|>\n<|im_start|>user\n{\n    'id': '657eafdeef3d6763710dffa2',\n     'url': '/images/657eafdeef3d6763710dffa2'\n}\n{\n    'id': '657eafdeef3d6763710dffa6',\n     'url': '/images/657eafdeef3d6763710dffa6'\n}\n</image>\nThese are 'hostolocs'.<|im_end|>\n<|im_start|>assistant\n<execute>\nlist_image_ids = ['657eafdeef3d6763710dffa2', '657eafdeef3d6763710dffa6',]\nclassname = ‘hostolocs’ \nresponse = teach_model(classname, list_image_ids)\nprint(response)\n</execute> <|im_end|>\n<|im_start|>user\n{\n    'id': '657eafdeef3d6763710dffa2',\n     'url': '/images/657eafdeef3d6763710dffa2'\n}\n</image>\nThis is a 'vignetter'.<|im_end|>\n<|im_start|>assistant\n<execute>\nlist_image_ids = ['657eafdeef3d6763710dffa2']\nclassname = 'vignetter'\nresponse = teach_model(classname, list_image_ids)\nprint(response)\n</execute> <|im_end|>\n\n<|im_start|>user\nWhat are the difference between a ‘idasaki’ and ‘oogabboba’?.<|im_end|>\n<|im_start|>assistant\n<execute>\nconcept_1 = ‘idasaki’\nconcept_2 = 'oogabboba'\nresponse = compare_concepts(concept_1, concept_2)\nprint(response)\n</execute> <|im_end|>\n<|im_start|>user\n{\n    'id': '657eafdeef3d6763710dffa2',\n     'url': '/images/657eafdeef3d6763710dffa2'\n}\n</image>\nThis is a hooldde.<|im_end|>\n<|im_start|>assistant\n<execute>\nlist_image_ids = ['657eafdeef3d6763710dffa2']\nclassname = 'hooldde'\nresponse = teach_model(classname, list_image_ids)\nprint(response)\n</execute> <|im_end|>\n<|im_start|>user\n\n{\n    'id': '657eafdeef3d6763710dffa2',\n     'url': '/images/657eafdeef3d6763710dffa2'\n}\n\n{\n    'id': '657eafdeef3d6763710dffb3’,\n     'url': '/images/657eafdeef3d6763710dffb3’\n}\nWhat are the difference between these two images?.<|im_end|>\n<|im_start|>assistant\n<execute>\nimage_id_1 = ‘657eafdeef3d6763710dffa2’\nimage_id_2 = ‘657eafdeef3d6763710dffb3’\nresponse = compare_images(image_id_1, image_id_2)\nprint(response)\n</execute> <|im_end|>\n<|im_start|>user\nReset server<|im_end|>\n<|im_start|>assistant\n<execute>\nreset_from_scratch = False\nreset_server(reset_from_scratch)\n</execute> <|im_end|>\n<|im_start|>user\nReset server the server from scratch<|im_end|>\n<|im_start|>assistant\n<execute>\nreset_from_scratch = True\nreset_server(reset_from_scratch)\n</execute> <|im_end|>\n\n",
      "promptExamples" : [
        {
          "title": "What is the object inside the image?",
          "prompt": "\n<image>{\"url\": \"/images/65ea6ea14cdcc12d004ed385\",\"id\": \"65ea6ea14cdcc12d004ed385\"}</image> \n What is this?"
        },
        {
          "title": "What is the activity inside the video?",
          "prompt": "\n<video>{\"url\": \"/videos/65e9de4e518d42656415536e\",\"id\": \"65e9de4e518d42656415536e\"}</video> What is the action inside the video?"
        },
        {
          "title": "What are the differences between the two images?",
          "prompt": "<image>{\"url\": \"/images/65ea6ea14cdcc12d004ed385\",\"id\": \"65ea6ea14cdcc12d004ed385\"}</image> What are the differences between the two images?"
        },
        {
          "title": "What are the differences between the two concepts?",
          "prompt": "What are the differences between a 'shovel' and a 'vultureleader'?"
        }
      ],
      "parameters": {
        "temperature": 0,
        "top_p": 0.95,
        "max_new_tokens": 1024,
        "stop": ["<|im_start|>", "<|im_end|>", "</execute>"]
      }     
  }
]`

OLD_MODELS=`[]`# any removed models, `{ name: string, displayName?: string, id?: string }`
TASK_MODEL= # name of the model used for tasks such as summarizing title, creating query, etc.

PUBLIC_ORIGIN=https://blender02.cs.illinois.edu/
ORIGIN=https://blender02.cs.illinois.edu/
PROTOCOL_HEADER=x-forwarded-proto 
HOST_HEADER=x-forwarded-host
PUBLIC_SHARE_PREFIX=#https://hf.co/chat
PUBLIC_GOOGLE_ANALYTICS_ID=#G-XXXXXXXX / Leave empty to disable
PUBLIC_ANNOUNCEMENT_BANNERS=`[
]`

PARQUET_EXPORT_DATASET=
PARQUET_EXPORT_HF_TOKEN=
PARQUET_EXPORT_SECRET=

OLD_MODELS=`[]`# any removed models, `{ name: string, displayName?: string, id?: string }`
TASK_MODEL= # name of the model used for tasks such as summarizing title, creating query, etc.

PUBLIC_ORIGIN=#https://huggingface.co
PUBLIC_SHARE_PREFIX=#https://hf.co/chat
PUBLIC_GOOGLE_ANALYTICS_ID=#G-XXXXXXXX / Leave empty to disable
PUBLIC_ANNOUNCEMENT_BANNERS=`[
]`

PARQUET_EXPORT_DATASET=
PARQUET_EXPORT_HF_TOKEN=
PARQUET_EXPORT_SECRET=


# used to activate search with web functionality. disabled if none are defined. choose one of the following:
YDC_API_KEY=#your docs.you.com api key here
SERPER_API_KEY=#your serper.dev api key here
SERPAPI_KEY=#your serpapi key here
SERPSTACK_API_KEY=#your serpstack api key here
USE_LOCAL_WEBSEARCH=#set to true to parse google results yourself, overrides other API keys


WEBSEARCH_ALLOWLIST=`[]` # if it's defined, allow websites from only this list.
WEBSEARCH_BLOCKLIST=`[]` # if it's defined, block websites from this list.


RATE_LIMIT= # requests per minute
MESSAGES_BEFORE_LOGIN=# how many messages a user can send in a conversation before having to login. set to 0 to force login right away

PUBLIC_APP_NAME=ECOLE MIRACLE # name used as title throughout the app
PUBLIC_APP_ASSETS=codeact # used to find logos & favicons in static/$PUBLIC_APP_ASSETS
PUBLIC_APP_COLOR=black #blue # can be any of tailwind colors: https://tailwindcss.com/docs/customizing-colors#default-color-palette
PUBLIC_APP_DESCRIPTION="Visual Concept Recognition from Images and Videos" # description used throughout the app (if not set, a default one will be used)
PUBLIC_APP_DATA_SHARING=#set to 1 to enable options & text regarding data sharing
PUBLIC_APP_DISCLAIMER=#set to 1 to show a disclaimer on login page
LLM_SUMMERIZATION=true
