# Use .env.local to change these variables
# DO NOT EDIT THIS FILE WITH SENSITIVE DATA

MONGODB_URL=mongodb://mintagent:mintagentuiuc@mongo-chat-ui:27017/
MONGODB_DB_NAME=chat-ui
MONGODB_DIRECT_CONNECTION=false

BODY_SIZE_LIMIT=0

COOKIE_NAME=hf-chat
HF_TOKEN=#hf_<token> from from https://huggingface.co/settings/token
HF_API_ROOT=https://api-inference.huggingface.co/models
OPENAI_API_KEY=#your openai api key here

HF_ACCESS_TOKEN=#LEGACY! Use HF_TOKEN instead

# used to activate search with web functionality. disabled if none are defined. choose one of the following:
YDC_API_KEY=#your docs.you.com api key here
SERPER_API_KEY=#your serper.dev api key here
SERPAPI_KEY=#your serpapi key here

# used to handling images in the chat
IMAGE_SERVER_URL=http://image-server:80
IMAGE_SERVER_TOKEN=available
IMAGE_SERVER_DB_NAME=image_database

# VIDEO_SERVER_URL
VIDEO_SERVER_URL=http://uiuc-paxion:80
JUPYTER_API_URL=http://128.174.136.21:8008


# Parameters to enable open id login
OPENID_CONFIG=`{
  "PROVIDER_URL": "",
  "CLIENT_ID": "",
  "CLIENT_SECRET": "",
  "SCOPES": ""
}`

# /!\ legacy openid settings, prefer the config above
OPENID_CLIENT_ID=
OPENID_CLIENT_SECRET=
OPENID_SCOPES="openid profile" # Add "email" for some providers like Google that do not provide preferred_username
OPENID_PROVIDER_URL=https://huggingface.co # for Google, use https://accounts.google.com
OPENID_TOLERANCE=
OPENID_RESOURCE=

# Parameters to enable a global mTLS context for client fetch requests
USE_CLIENT_CERTIFICATE=false
CERT_PATH=#
KEY_PATH=#
CA_PATH=#
CLIENT_KEY_PASSWORD=#
REJECT_UNAUTHORIZED=true


N_EXECUTION_LIMIT=7 # Number of turns allowed for LLM's self-execution.


# 'name', 'userMessageToken', 'assistantMessageToken' are required
MODELS=`[
  {   
      "endpoints": [
          {
            "type" : "openai",
            "baseURL": "http://cs-xing6-01.cs.illinois.edu:30000/v1"
          }
        ],
        "name": "CodeActAgent-Mistral-7b-v0.1",
        "modelUrl": "https://huggingface.co/xingyaoww/CodeActAgent-Mistral-7b-v0.1",
        "websiteUrl": "https://huggingface.co/xingyaoww/CodeActAgent-Mistral-7b-v0.1",

      "userMessageToken": "<|im_start|>user\n",
      "userMessageEndToken": "<|im_end|>",
      "assistantMessageToken": "<|im_start|>assistant\n",
      "assistantMessageEndToken": "<|im_end|>",
      "preprompt": "<|im_start|>system\n- You are a helpful assistant.\n- You can answer questions in natural language, display images through <image> tags (e.g., <image> [image_id] </image>), and execute Python code through <execute> tags (e.g., <execute> print(“hello world”) </execute>). \nYou have access to the following tools (pre-imported Python functions):\n\n[1] what_is_object(image_id: str) -> dict\nDescription: Identifies the primary subject or feature in the image. It can be used to answer questions like 'What is this?', 'What is inside this image?' \nInput Variables: image_id: The unique identifier of the image.\nExample: <execute>what_is_object('12345abcde')</execute>\n\n[2] difference_concepts(concept_1:str, concept_2:str) -> dict\nDescription: Identifies the differences between two images. It can be used to answer questions like 'What is the difference between the two concepts?', 'What is the difference between [concept 1] and [concept 2]?'\nInput Variables: concept_1: The first concept; concept_2: The second concept\nExample: <execute>difference_concepts(‘fox’, ‘cat’)</execute>\n\n[3] difference_images(image_id_1:str, image_id_2:str) -> dict\nDescription: Identifies the differences between two images. It can be used to answer questions like 'What is the difference between these two images?', 'What is the difference between the two images?’\nInput Variables: image_id_1: The unique identifier of the first image; image_id_2: The unique identifier of the second image.\nExample: <execute>difference_images(‘12345abcde', '67890fghij')</execute>\n\n[4] add_attributes(image_id: str, classname: str, attributes: list) -> dict\nDescription: Adds specified attributes to a given class (concept) in the image.\nInput Variables: image_id: The unique identifier of the image; classname: The class; attributes: Attributes to be added.\nExample: <execute>add_attributes('12345abcde', 'dog', ['brown', 'small'])</execute>\n\n[5] remove_attributes(image_id: str, classname: str, attributes: list) -> dict\nDescription: Removes specified attributes from a given class in the image.\nInput Variables: image_id: The unique identifier of the image; classname: The class; attributes: Attributes to be removed.\nExample: <execute>remove_attributes('12345abcde', 'car', ['red', 'rusty'])</execute>\n\n[6] add_new_concept(image_id: str, correct_concept: str, wrong_concept: str) -> dict\n Description: Replace an old class with a new class in the image. Use this when the user say something like 'no this is not a [wrong_concept] but this is a [correct_concept]', 'This is the [correct_concept].' 'No, this is a [correct_concept]'. \nInput Variables: image_id: The unique identifier of the image; correct_concept: New class input; wrong_concept: Old class to be replaced.\n Example: <execute>old_concept = “Gas Car”\nnew_concept= “Electric Car”\nadd_new_concept('12345abcde', new_concept, old_concept)</execute>\n\n[8] grounding_object_in_image(image_id: str, description: str, ground_tokens: str) -> dict\nDescription: This function identifies and marks specific objects in an image based on the provided description. User can ask something like 'Can you get the ball inside the image?', 'Can you ground the bird inside the image?', 'Can you find the dog inside the image?'.\nInput Variables: image_id: The unique identifier of the image; description: A description of the image. ground_tokens: A comma-separated list of objects to be identified and marked in the image.\nExample: <execute> \ndescription='blue colar'\nground_tokens= 'blue colar'\ngrounding_object_in_image('12345abcde', description, ground_tokens)\n</execute>\n \n[9] get_attributes(classname: str) -> dict\nDescription: Retrieves attributes associated with a given classname.\nInput Variables: classname: The name of the class for which attributes are being retrieved.\nExample: <execute>get_attributes('vehicle')</execute> \n \n[10] reset_server() -> dict\nDescription: Reset the backend server.\n\n[11] detect_activity_inside_video(video_id:str) -> dict\nDescription: Detect activity inside the video.\nInput Variables: video_id: The id of the video.\nExample: <execute> detect_activity_inside_video('123abc')</execute> \n\n[12] get_similar_videos(video_id: str) -> dict\nDescription: Get similar videos has the same action with the current video.\nInput Variables: video_id: The id of the video.\nExample: <execute> get_similar_videos('123abc')</execute> <|im_start|>user\n{\n    'id': '657eafdeef3d6763710dffa2/',\n     'url': '/images/657eafdeef3d6763710dffa2'\n}\n</image>\nwhat is this? <|im_end|>\n<|im_start|>assistant\nimage_id = '657eafdeef3d6763710dffa2'\nresponse = what_is_object(image_id)\nprint(response)\n</execute> <|im_end|>\n<|im_start|>user\nWhat is the difference between a cat and a dog? <|im_end|>\n<|im_start|>assistant\n<execute>\nimage_id_1 = '657eafdeef3d6763710dffa2'\nimage_id_2 = '657eafdeef3d6763710dffb3'\ndifference_concepts(image_id_1, image_id_2)\n</execute> <|im_end|>\n<|im_start|>user\nNo, this is not a 'coyote', but it is a 'grey wolf'. <|im_end|>\n<|im_start|>assistant\n<execute>\nnew_concept = 'grey wolf'\nold_concept= 'coyote'\nresponse = add_new_concept(image_id, new_concept, old_concept)\nprint(response)\n</execute> <|im_end|>\n<|im_start|>user\nCan you ground soft, dense fur inside the cat image?\n<|im_start|>assistant\n<execute>\nimage_id = '657eafdeef3d6763710dffa2'\ndescription = 'soft, dense fur'\nground_tokens =  'soft, dense fur'\ngrounding_object_in_image(image_id, description, ground_tokens)\n</execute> <|im_end|>\n",
      "promptExamples" : [
        {
          "title": "Predict an object in the image.",
          "prompt": "\n<image>{\"url\": \"/images/65aa9ddc5e2b33e0430fb70e\",\"id\": \"65aa9ddc5e2b33e0430fb70e\"}</image> \n What is this?"
        },{
          "title": "What attributes are considered in the prediction?",
          "prompt": "\n<image>{\"url\": \"/images/65aa9ddc5e2b33e0430fb70e\",\"id\": \"65aa9ddc5e2b33e0430fb70e\"}</image> Why is that?"
        },
        {
          "title": "What are the list of attributes for a given class?",
          "prompt": "What attributes does a 'bee' have?"
        }
      ],
      "parameters": {
        "temperature": 0.1,
        "top_p": 0.95,
        "max_new_tokens": 1024,
        "stop": ["<|im_start|>", "<|im_end|>", "</execute>"]
      }     
  }
]`

OLD_MODELS=`[]`# any removed models, `{ name: string, displayName?: string, id?: string }`
TASK_MODEL= # name of the model used for tasks such as summarizing title, creating query, etc.

PUBLIC_ORIGIN=https://blender02.cs.illinois.edu/
ORIGIN=https://blender02.cs.illinois.edu/
PROTOCOL_HEADER=x-forwarded-proto 
HOST_HEADER=x-forwarded-host
PUBLIC_SHARE_PREFIX=#https://hf.co/chat
PUBLIC_GOOGLE_ANALYTICS_ID=#G-XXXXXXXX / Leave empty to disable
PUBLIC_ANNOUNCEMENT_BANNERS=`[
]`

PARQUET_EXPORT_DATASET=
PARQUET_EXPORT_HF_TOKEN=
PARQUET_EXPORT_SECRET=

OLD_MODELS=`[]`# any removed models, `{ name: string, displayName?: string, id?: string }`
TASK_MODEL= # name of the model used for tasks such as summarizing title, creating query, etc.

PUBLIC_ORIGIN=#https://huggingface.co
PUBLIC_SHARE_PREFIX=#https://hf.co/chat
PUBLIC_GOOGLE_ANALYTICS_ID=#G-XXXXXXXX / Leave empty to disable
PUBLIC_ANNOUNCEMENT_BANNERS=`[
]`

PARQUET_EXPORT_DATASET=
PARQUET_EXPORT_HF_TOKEN=
PARQUET_EXPORT_SECRET=


# used to activate search with web functionality. disabled if none are defined. choose one of the following:
YDC_API_KEY=#your docs.you.com api key here
SERPER_API_KEY=#your serper.dev api key here
SERPAPI_KEY=#your serpapi key here
SERPSTACK_API_KEY=#your serpstack api key here
USE_LOCAL_WEBSEARCH=#set to true to parse google results yourself, overrides other API keys


WEBSEARCH_ALLOWLIST=`[]` # if it's defined, allow websites from only this list.
WEBSEARCH_BLOCKLIST=`[]` # if it's defined, block websites from this list.


RATE_LIMIT= # requests per minute
MESSAGES_BEFORE_LOGIN=# how many messages a user can send in a conversation before having to login. set to 0 to force login right away

PUBLIC_APP_NAME=ECOLE MIRACLE # name used as title throughout the app
PUBLIC_APP_ASSETS=codeact # used to find logos & favicons in static/$PUBLIC_APP_ASSETS
PUBLIC_APP_COLOR=black #blue # can be any of tailwind colors: https://tailwindcss.com/docs/customizing-colors#default-color-palette
PUBLIC_APP_DESCRIPTION="Visual Concept Recognition from Images and Videos" # description used throughout the app (if not set, a default one will be used)
PUBLIC_APP_DATA_SHARING=#set to 1 to enable options & text regarding data sharing
PUBLIC_APP_DISCLAIMER=#set to 1 to show a disclaimer on login page
LLM_SUMMERIZATION=true
