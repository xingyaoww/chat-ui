# Use .env.local to change these variables
# DO NOT EDIT THIS FILE WITH SENSITIVE DATA

MONGODB_URL=mongodb://mintagent:mintagentuiuc@mongo-chat-ui:27017/
MONGODB_DB_NAME=chat-ui
MONGODB_DIRECT_CONNECTION=false

COOKIE_NAME=hf-chat
HF_ACCESS_TOKEN=#hf_<token> from from https://huggingface.co/settings/token
HF_API_ROOT=https://api-inference.huggingface.co/models

# used to activate search with web functionality. disabled if none are defined. choose one of the following:
YDC_API_KEY=#your docs.you.com api key here
SERPER_API_KEY=#your serper.dev api key here
SERPAPI_KEY=#your serpapi key here

# used to handling images in the chat
IMAGE_SERVER_URL=http://image-server:80
IMAGE_SERVER_TOKEN=available
IMAGE_SERVER_DB_NAME=image_database

JUPYTER_API_URL=http://128.174.136.21:8008


# Parameters to enable open id login
OPENID_CONFIG=`{
  "PROVIDER_URL": "",
  "CLIENT_ID": "",
  "CLIENT_SECRET": "",
  "SCOPES": ""
}`

# /!\ legacy openid settings, prefer the config above
OPENID_CLIENT_ID=
OPENID_CLIENT_SECRET=
OPENID_SCOPES="openid profile" # Add "email" for some providers like Google that do not provide preferred_username
OPENID_PROVIDER_URL=https://huggingface.co # for Google, use https://accounts.google.com
OPENID_TOLERANCE=
OPENID_RESOURCE=

# Parameters to enable a global mTLS context for client fetch requests
USE_CLIENT_CERTIFICATE=false
CERT_PATH=#
KEY_PATH=#
CA_PATH=#
CLIENT_KEY_PASSWORD=#
REJECT_UNAUTHORIZED=true



# 'name', 'userMessageToken', 'assistantMessageToken' are required
MODELS=`[
  {   
      "endpoints": [
        {
          "url": "http://cs-xing6-01.cs.illinois.edu:8080"
        }
      ],
      "name": "MINT-Agent",
      "userMessageToken": "<|im_start|>user\n",
      "userMessageEndToken": "<|im_end|>",
      "assistantMessageToken": "<|im_start|>assistant\n",
      "assistantMessageEndToken": "<|im_end|>",
      "preprompt": "<|im_start|>system\n You are a helpful assistant.\n You can answer questions in natural language, display images through <image> tags (e.g., <image> [image_id] </image>), and execute Python code through <execute> tags (e.g., <execute> print(“hello world”) </execute>). \n\n You have access to the following tools (pre-imported Python functions):\n [1] label_object(image_id: str) -> dict\nDescription: Retrieves an image as a base64 encoded string and labels objects in the image.\nInput Variables: image_id: The unique identifier of the image.\nExample: <execute> label_object('12345abcde') </execute>\n\n[2] what_is_object(image_id: str) -> dict\nDescription: Identifies the primary subject or feature in the image. It can be used to answer questions like 'What is this?'.\nInput Variables: image_id: The unique identifier of the image.\nExample: <execute>what_is_object('12345abcde')</execute>\n\n[3] explain_concept(image_id: str) -> dict\nDescription: Explains the context or reason behind the primary subject or feature in the image. It can be used to answer questions like 'Why this is an [object name]?'.\nInput Variables: image_id: The unique identifier of the image.\nExample: <execute>explain_concept('12345abcde')</execute>\n\n[4] add_attributes(image_id: str, classname: str, attributes: list) -> dict\nDescription: Adds specified attributes to a given class (concept) in the image.\nInput Variables: image_id: The unique identifier of the image; classname: The class; attributes: Attributes to be added.\nExample: <execute>add_attributes('12345abcde', 'dog', ['brown', 'small'])</execute>\n\n[5] remove_attributes(image_id: str, classname: str, attributes: list) -> dict\nDescription: Removes specified attributes from a given class in the image.\nInput Variables: image_id: The unique identifier of the image; classname: The class; attributes: Attributes to be removed.\nExample: <execute>remove_attributes('12345abcde', 'car', ['red', 'rusty'])</execute>\n\n[6] add_new_concept(image_id: str, classname: str, old_classname: str) -> dict\nDescription: Replace an old class with a new class in the image. Use this when the user say something like 'no this is not a 'old_class_name' but this is a 'new_class_name''.\nInput Variables: image_id: The unique identifier of the image; classname: New class; old_classname: Old class to be replaced.\nExample: <execute>add_new_concept('12345abcde', 'electric car', 'car')</execute>\n\n[7] find_relation(image_id: str) -> dict\nDescription: Find the relation inside the image\nInput Variables: image_id: The unique identifier of the image.\nExample: <execute> find_relation('12345abcde')</execute> \n\n[8] grounding_object_in_image(image_id: str, description: str, ground_tokens: str) -> dict\nDescription: This function identifies and marks specific objects in an image based on the provided description.\nInput Variables: image_id: The unique identifier of the image; description: A textual description of the scene or objects in the image. ground_tokens: A comma-separated list of objects to be identified and marked in the image.\nExample: <execute> grounding_object_in_image('12345abcde', 'horses', 'horse')</execute>\n\n[9] get_attributes(classname: str) -> dict\nDescription: Retrieves attributes associated with a given classname.\nInput Variables: classname: The name of the class for which attributes are being retrieved.\nExample: <execute>get_attributes('vehicle')</execute> \n\n[10] reset_server() -> dict\nDescription: Reset the backend server.\nExample: <execute>reset_server()</execute> <|im_end|>\n<|im_start|>user\n<image>\n{\n  'id': '657eafdeef3d6763710dffa2/',\n   'url': '/images/657eafdeef3d6763710dffa2'\n}\n</image>\nwhat is this? <|im_end|>\n<|im_start|>assistant\n<execute>\nimage_id = '657eafdeef3d6763710dffa2'\nresponse = what_is_object(image_id)\nprint(response)\n</execute>\nThis is a 'canoe' <|im_end|>\n<|im_start|>user\nNo, this is not a canoe, but it is a kayak. <|im_end|>\n<|im_start|>assistant\n<execute>\nresponse = add_new_concept(image_id, 'kayak', 'canoe')\nprint(response)\n</execute>\nI cannot find 'kayak' in my knowledge base. It is now added. The new classification is 'kayak'\n<|im_end|>",
      "parameters": {
        "temperature": 0.1,
        "top_p": 0.95,
        "truncate": 31744,
        "max_new_tokens": 1024,
        "stop": ["<|im_start|>", "<|im_end|>", "</execute>"]
      }     
  }
]`
OLD_MODELS=`[]`# any removed models, `{ name: string, displayName?: string, id?: string }`
TASK_MODEL='' # name of the model used for tasks such as summarizing title, creating query, etc.

PUBLIC_ORIGIN=#https://huggingface.co
PUBLIC_SHARE_PREFIX=#https://hf.co/chat
PUBLIC_GOOGLE_ANALYTICS_ID=#G-XXXXXXXX / Leave empty to disable
PUBLIC_ANNOUNCEMENT_BANNERS=`[
]`

PARQUET_EXPORT_DATASET=
PARQUET_EXPORT_HF_TOKEN=
PARQUET_EXPORT_SECRET=

RATE_LIMIT= # requests per minute
MESSAGES_BEFORE_LOGIN=# how many messages a user can send in a conversation before having to login. set to 0 to force login right away

PUBLIC_APP_NAME=ECOLE # name used as title throughout the app
PUBLIC_APP_ASSETS=chatui # used to find logos & favicons in static/$PUBLIC_APP_ASSETS
PUBLIC_APP_COLOR=blue # can be any of tailwind colors: https://tailwindcss.com/docs/customizing-colors#default-color-palette
PUBLIC_APP_DESCRIPTION=# description used throughout the app (if not set, a default one will be used)
PUBLIC_APP_DATA_SHARING=#set to 1 to enable options & text regarding data sharing
PUBLIC_APP_DISCLAIMER=0#set to 1 to show a disclaimer on login page
LLM_SUMMERIZATION=true

# PUBLIC_APP_NAME=HuggingChat
# PUBLIC_APP_ASSETS=huggingchat
# PUBLIC_APP_COLOR=yellow
PUBLIC_APP_DESCRIPTION=""
# PUBLIC_APP_DATA_SHARING=1
# PUBLIC_APP_DISCLAIMER=1